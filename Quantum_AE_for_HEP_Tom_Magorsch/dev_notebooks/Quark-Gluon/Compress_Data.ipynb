{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78501a2e-af16-4326-8b0c-3f1ef400ed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 16:12:32.771355: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-24 16:12:32.771378: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/tom/.conda/envs/tfq/lib/python3.9/site-packages/cirq/ops/gateset.py:376: UserWarning: v0.14.1 is the last release `cirq.GlobalPhaseGate` is included by default. If you were relying on this behavior, you can include a `cirq.GlobalPhaseGate` in your `*gates`. If not, then you can ignore this warning. It will be removed in v0.16\n",
      "  warnings.warn(\n",
      "2022-08-24 16:12:34.217340: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-24 16:12:34.217364: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-24 16:12:34.217382: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tomskopfbahnhof): /proc/driver/nvidia/version does not exist\n",
      "2022-08-24 16:12:34.217626: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "from hep_VQAE import data_preprocessing as dp\n",
    "from hep_VQAE import CAE as cae\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1826c698-be86-42bd-8281-c681c569c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"../../data/quark-gluon/quark-gluon_train-set_n793900.hdf5\",\"r\")\n",
    "f2 = h5py.File(\"../../data/quark-gluon/quark-gluon_test-set_n10000.hdf5\",\"r\")\n",
    "#f3 = h5py.File(\"data/quark-gluon/quark-gluon_test-set_n139306.hdf5\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b42a496-8337-47a9-8170-05d61a7b703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = f.get('X_jets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "806f8495-db63-4eeb-9e19-f7a441a45cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = f.get('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f738b550-54eb-490d-9259-409598700ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['X_jets', 'm0', 'pt', 'y']>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0340cb97-b4c9-48be-8f87-f2aab9236339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793900, 125, 125, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e61f5df-e390-4256-bdb1-92e999f6822c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "793900 // 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c97b5ae-8071-4e33-ac66-8a938c29ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ddc5aad-0988-45ff-8b03-dd879e262767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Sequence) :\n",
    "  \n",
    "  def __init__(self, hdf5_file, batch_size) :\n",
    "    self.hdf5_file = hdf5_file\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "  # Länge der Trainingsdaten (Anzahl der Batches)\n",
    "  def __len__(self) :\n",
    "    return x_train.shape[0]//self.batch_size\n",
    "  \n",
    "  # Lädt Bilder anhand der Pfade aus dem Trainingsarray\n",
    "  def __getitem__(self, idx) :\n",
    "    \n",
    "    return self.hdf5_file[idx * self.batch_size: (idx + 1) * self.batch_size]/2222.665, self.hdf5_file[idx * self.batch_size: (idx + 1) * self.batch_size]/2222.665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d42d08d-c762-4427-8779-c061bc702bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = Generator(x_train, 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2934adb-386d-4556-9b49-61df0a75f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cae.Convolutional_Autoencoder2(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79ff7752-42f4-4a76-a77f-c4c19db3e24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 42, 42, 8)         224       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 20, 20, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 12808     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,336\n",
      "Trainable params: 37,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5403bb80-136e-49f3-8653-2c17c84a2617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/.conda/envs/tfq/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "739e2947-7f29-4fc3-a714-ec288fb1218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54851/565034597.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model.fit_generator(traingen,epochs=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "882/882 [==============================] - 5743s 7s/step - loss: 6.3910e-04\n",
      "Epoch 2/2\n",
      "882/882 [==============================] - 5389s 6s/step - loss: 4.3068e-11\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(traingen,epochs=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "795dfb26-4241-4ccf-8cb3-25e861077450",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = f2.get('X')\n",
    "y_test = f2.get('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40090f20-2528-42ca-a694-705097545f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 125, 125, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2cbd300-e755-4513-8ada-248a38ea12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(x):\n",
    "    pred = model.predict(x)\n",
    "    return np.mean(np.abs(x - pred)**2,axis=(1,2,3))\n",
    "\n",
    "def recon_acc(x):\n",
    "    return 1 - mae(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f226136c-a5bd-4b9d-930f-1d150f262076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 125, 125, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:2000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c4b893f-1a5c-4add-bddb-18175b03748e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 125, 125, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[8000:10000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9069c887-4381-4f61-8fc9-6f2aaccfd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerrooo = recon_acc(x_test[:2000])\n",
    "one = recon_acc(x_test[8000:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93305172-b2ec-41b4-ac51-8ea7bb413edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zerrooo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c064fd10-78d6-4e4b-bef9-379e1be7b733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f46674d8-8e63-46f6-ad67-c74ed5122358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999977\n",
      "0.99999565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0ce00e12b0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.median(zerrooo))\n",
    "bins = np.histogram(np.hstack((zerrooo, one)), bins=150)[1]\n",
    "bins = np.arange(0.999990,0.999999,0.000001)\n",
    "plt.hist(zerrooo, histtype='step', label=\"zero\",bins=bins)#,bins=[0.0004,0.0005,0.0006,0.0007,0.0008,0.0009,0.001,0.0011,0.0012,0.0013])\n",
    "print(np.median(one))\n",
    "plt.hist(one, histtype='step', label=\"one\",bins=bins)#,bins=[0.0004,0.0005,0.0006,0.0007,0.0008,0.0009,0.001,0.0011,0.0012,0.0013])\n",
    "plt.xlabel(\"Reconstruction error\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d791b25-e194-4b04-835c-8db22badad01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793900"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ade2300-cb30-452c-bd9e-a5c5b289aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a6cc057-15cb-4765-aa64-c13556e7fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = x_train.shape[0]/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be3006a2-5955-4bd3-b50d-6876358dbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsmall.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "450de7e8-9e0b-4216-a99f-6909edaa3690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466\r"
     ]
    }
   ],
   "source": [
    "fsmall = h5py.File('../../data/compressed3.hdf5','w')\n",
    "fsmall.create_dataset('X', shape=(x_train.shape[0],8))\n",
    "fsmall.create_dataset('y', shape=(x_train.shape[0], 1))\n",
    "\n",
    "for i in range(int(num_batches)):\n",
    "    fsmall['X'][i * batch_size: (i + 1) * batch_size] = model.encoder(x_train[i * batch_size: (i + 1) * batch_size]/2222.665)\n",
    "    fsmall['y'][i * batch_size: (i + 1) * batch_size] = y_train[i * batch_size: (i + 1) * batch_size].reshape((batch_size,1))\n",
    "    print(i, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91e651aa-fa93-40cc-9b41-795069193450",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sixes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m accs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m Ts:\n\u001b[0;32m---> 12\u001b[0m     accs\u001b[38;5;241m.\u001b[39mappend(\u001b[43macc_for_threshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(accs))\n\u001b[1;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(Ts, accs)\n",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36macc_for_threshold\u001b[0;34m(T)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# threes that are predicted three\u001b[39;00m\n\u001b[1;32m      5\u001b[0m num_three_right \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(one \u001b[38;5;241m<\u001b[39m T)\n\u001b[0;32m----> 6\u001b[0m acc \u001b[38;5;241m=\u001b[39m (num_six_right \u001b[38;5;241m+\u001b[39m num_three_right)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43msixes\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(threes))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sixes' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f70f8b4-8108-4712-b7b8-9c1c642ac84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222.665\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "maxx = 0\n",
    "minn = 10000000\n",
    "\n",
    "for i in range(int(num_batches)):\n",
    "    cmax = np.max(x_train[i * batch_size: (i + 1) * batch_size])\n",
    "    if cmax > maxx:\n",
    "        maxx = cmax\n",
    "    cmin = np.min(x_train[i * batch_size: (i + 1) * batch_size])\n",
    "    if cmin < minn:\n",
    "        minn = cmin\n",
    "    print(i)\n",
    "    \n",
    "print(maxx)\n",
    "print(minn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e1fe0c9-0a06-4c93-ba47-0fa889c14c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1600)              11200     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 15, 15, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 31, 31, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 62, 62, 16)       4624      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 125, 125, 8)      1160      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 125, 125, 3)       99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,475\n",
      "Trainable params: 72,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f712f9-9aa2-41a1-8cf7-8db05a635e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fa340be-7ad2-42ab-b567-02ca0b9fdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2828ada-8bde-4342-82cb-7e8a07b18cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Input(shape=(6,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14e459b0-bd7a-4f87-909d-0c883ced1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec073e8e-4d66-4760-8201-083b2d04033c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## from tensorflow.keras.models import Model\n",
    "newmodel = Model(inputs=x, outputs=model.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de805b17-801c-4a85-b7bd-e30ca45983b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfq",
   "language": "python",
   "name": "tfq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
